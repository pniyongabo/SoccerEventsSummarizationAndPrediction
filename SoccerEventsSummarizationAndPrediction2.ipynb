{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeLakZQKWsNo",
    "outputId": "d4d234fc-acd6-41e4-d1e4-dbe07861747f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 481 kB/s eta 0:00:01    |████████████████████████▋       | 9.2 MB 481 kB/s eta 0:00:06     |████████████████████████████    | 10.5 MB 481 kB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.56.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.25.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (52.0.0.post20210125)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.5-py3-none-any.whl size=12011738 sha256=5961b775e9d65b19724aeb78f6df912b357cf3569294cfbaf251f0d519b5c33e\n",
      "  Stored in directory: /private/var/folders/cj/s5f8hsj96095h24ccd2941j80000gn/T/pip-ephem-wheel-cache-sfechn48/wheels/51/19/da/a3885266a3c241aff0ad2eb674ae058fd34a4870fef1c0a5a0\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "id": "3joZV_-rWLXf",
    "outputId": "3baff05d-2723-414c-f322-f067c18eb47c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>lang</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source</th>\n",
       "      <th>len</th>\n",
       "      <th>Orig_Tweet</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Likes</th>\n",
       "      <th>RTs</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>UserMentionNames</th>\n",
       "      <th>UserMentionID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1013597060640145408</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:45</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>140</td>\n",
       "      <td>RT @Squawka: Only two goalkeepers have saved t...</td>\n",
       "      <td>Only two goalkeepers have saved three penaltie...</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>WorldCup,POR,ENG</td>\n",
       "      <td>Squawka Football</td>\n",
       "      <td>Squawka</td>\n",
       "      <td>Cayleb</td>\n",
       "      <td>Accra</td>\n",
       "      <td>861</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013597056219295744</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:44</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>139</td>\n",
       "      <td>RT @FCBarcelona: ?? @ivanrakitic scores the wi...</td>\n",
       "      <td>scores the winning penalty to send into the qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1031</td>\n",
       "      <td>WorldCup</td>\n",
       "      <td>FC Barcelona,Ivan Rakitic,HNS | CFF</td>\n",
       "      <td>FCBarcelona,ivanrakitic,HNS_CFF</td>\n",
       "      <td>Febri Aditya</td>\n",
       "      <td>Bogor</td>\n",
       "      <td>667</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1013597047482544130</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:42</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>107</td>\n",
       "      <td>RT @javierfernandez: Tonight we have big game....</td>\n",
       "      <td>Tonight we have big game</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "      <td>worldcup</td>\n",
       "      <td>Javier Fernandez,Evgeni Plushenko</td>\n",
       "      <td>javierfernandez,EvgeniPlushenko</td>\n",
       "      <td>??</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013597044198391808</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:41</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>142</td>\n",
       "      <td>We get stronger\\r\\nTurn the music up now\\r\\nWe...</td>\n",
       "      <td>We get stronger Turn the music up now We got t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PowerByEXO,WorldCup,FIFAStadiumDJ,XiuminLeague</td>\n",
       "      <td>EXO,FIFA World Cup ?</td>\n",
       "      <td>weareoneEXO,FIFAWorldCup</td>\n",
       "      <td>Frida Carrillo</td>\n",
       "      <td>Zapopan, Jalisco</td>\n",
       "      <td>17</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1013597039999926272</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-02 01:35:40</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>140</td>\n",
       "      <td>RT @Squawka: Only two goalkeepers have saved t...</td>\n",
       "      <td>Only two goalkeepers have saved three penaltie...</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>WorldCup,POR,ENG</td>\n",
       "      <td>Squawka Football</td>\n",
       "      <td>Squawka</td>\n",
       "      <td>tar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID lang                 Date               Source  len  \\\n",
       "0  1013597060640145408   en  2018-07-02 01:35:45  Twitter for Android  140   \n",
       "1  1013597056219295744   en  2018-07-02 01:35:44  Twitter for Android  139   \n",
       "2  1013597047482544130   en  2018-07-02 01:35:42  Twitter for Android  107   \n",
       "3  1013597044198391808   en  2018-07-02 01:35:41   Twitter Web Client  142   \n",
       "4  1013597039999926272   en  2018-07-02 01:35:40  Twitter for Android  140   \n",
       "\n",
       "                                          Orig_Tweet  \\\n",
       "0  RT @Squawka: Only two goalkeepers have saved t...   \n",
       "1  RT @FCBarcelona: ?? @ivanrakitic scores the wi...   \n",
       "2  RT @javierfernandez: Tonight we have big game....   \n",
       "3  We get stronger\\r\\nTurn the music up now\\r\\nWe...   \n",
       "4  RT @Squawka: Only two goalkeepers have saved t...   \n",
       "\n",
       "                                               Tweet  Likes   RTs  \\\n",
       "0  Only two goalkeepers have saved three penaltie...      0   477   \n",
       "1  scores the winning penalty to send into the qu...      0  1031   \n",
       "2                           Tonight we have big game      0   488   \n",
       "3  We get stronger Turn the music up now We got t...      0     0   \n",
       "4  Only two goalkeepers have saved three penaltie...      0   477   \n",
       "\n",
       "                                         Hashtags  \\\n",
       "0                                WorldCup,POR,ENG   \n",
       "1                                        WorldCup   \n",
       "2                                        worldcup   \n",
       "3  PowerByEXO,WorldCup,FIFAStadiumDJ,XiuminLeague   \n",
       "4                                WorldCup,POR,ENG   \n",
       "\n",
       "                      UserMentionNames                    UserMentionID  \\\n",
       "0                     Squawka Football                          Squawka   \n",
       "1  FC Barcelona,Ivan Rakitic,HNS | CFF  FCBarcelona,ivanrakitic,HNS_CFF   \n",
       "2    Javier Fernandez,Evgeni Plushenko  javierfernandez,EvgeniPlushenko   \n",
       "3                 EXO,FIFA World Cup ?         weareoneEXO,FIFAWorldCup   \n",
       "4                     Squawka Football                          Squawka   \n",
       "\n",
       "             Name             Place  Followers  Friends  \n",
       "0          Cayleb             Accra        861      828  \n",
       "1    Febri Aditya             Bogor        667      686  \n",
       "2              ??               NaN         65       67  \n",
       "3  Frida Carrillo  Zapopan, Jalisco         17       89  \n",
       "4             tar               NaN        137      216  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import spacy\n",
    "#nlp=spacy.load('en_core_web_sm')\n",
    "df=pd.read_csv('kaggle-world-cup-2018-tweets.csv')\n",
    "print(df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vLN-LYOwWLXs"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "#print(df.size)\n",
    "#dd = df.dropna(subset=['Tweet']) # drop rows only if the value in 'Tweet' column is missing\n",
    "#dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hppqDvZBWLXt",
    "outputId": "1a07bc3a-647c-4137-de1b-cdd04ef7794f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287535\n"
     ]
    }
   ],
   "source": [
    "my_list=list(df['Tweet'])\n",
    "print(len(list(my_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Fmj4Ic_lWLXu"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6c8052df5c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'internals'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#from nltk.stem.snowball import SnowballStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnowball\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSnowballStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnew_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages/nltk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_shell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtkinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[0;31m# Aliases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m \u001b[0m_downloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, server_index_url, download_dir)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;31m# decide where we're going to save things to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_download_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;31m#/////////////////////////////////////////////////////////////////\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/nlpfinal/lib/python3.7/site-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdefault_download_dir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;31m# Check if we have sufficient permissions to install in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;31m# variety of system-wide locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mnltkdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m             if (os.path.exists(nltkdir) and\n\u001b[1;32m    943\u001b[0m                 nltk.internals.is_writable(nltkdir)):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nltk' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('internals')\n",
    "#from nltk.stem.snowball import SnowballStemmer\n",
    "S=nltk.stem.snowball.SnowballStemmer('english')\n",
    "new_list=[]\n",
    "for i in my_list:\n",
    "    tweet=nlp(str(i))\n",
    "    my_tweet=[]\n",
    "    for j in tweet:\n",
    "        if j.text in nlp.Defaults.stop_words or j.is_punct is True:\n",
    "            pass\n",
    "        else:\n",
    "            my_tweet.append(S.stem(j.text.lower()))\n",
    "    new_tweet=' '.join(my_tweet)\n",
    "    new_list.append(new_tweet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/content/drive/MyDrive/ColabData/new_list.pickle', 'wb') as filehandle:\n",
    "    # store the data as binary data stream\n",
    "    pickle.dump(new_list, filehandle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8bdd7fw4XeY"
   },
   "outputs": [],
   "source": [
    "new_list=[]\n",
    "with open('/content/drive/MyDrive/ColabData/new_list.pickle', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    new_list = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gN7YLfefWLXv"
   },
   "outputs": [],
   "source": [
    "y=[]\n",
    "x=[]\n",
    "indexes=[]\n",
    "for index,i in enumerate(new_list):\n",
    "    if 'foul' in i:\n",
    "        if i not in x:\n",
    "            y.append(0)\n",
    "            x.append(i)\n",
    "            indexes.append(index)\n",
    "    elif 'penalti' in i:\n",
    "        if i not in x:\n",
    "            y.append(1)\n",
    "            x.append(i)\n",
    "            indexes.append(index)\n",
    "    elif 'goal' in i:\n",
    "        if i not in x:\n",
    "            y.append(2)\n",
    "            x.append(i)\n",
    "            indexes.append(index)\n",
    "    elif 'red card' in i:\n",
    "        if i not in x:\n",
    "            y.append(3)\n",
    "            x.append(i)\n",
    "            indexes.append(index)\n",
    "    elif 'yellow card' in i :\n",
    "        if i not in x:\n",
    "            y.append(4)\n",
    "            x.append(i)\n",
    "            indexes.append(index)\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_F_E7taOWLXw"
   },
   "outputs": [],
   "source": [
    "Y=0\n",
    "r=0\n",
    "f=0\n",
    "p=0\n",
    "g=0\n",
    "for i in y:\n",
    "    if i==0:\n",
    "        f+=1\n",
    "    if i==1:\n",
    "        p+=1\n",
    "    if i==2:\n",
    "        g+=1\n",
    "    if i==3:\n",
    "        r+=1\n",
    "    if i==4:\n",
    "        Y+=1\n",
    "print('yellow card: '+str(Y))\n",
    "print('fouls: '+str(f))\n",
    "print('red card: '+str(r))\n",
    "print('goals: '+str(g))\n",
    "print('penalties: '+str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaDhGWpd77Yi"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns \r\n",
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCtsB8PsWLXx"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "x=tfidf.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ed5BsIlYWLXx"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "\n",
    "X, Y = smote.fit_resample(x,y)\n",
    "from collections import Counter\n",
    "print(\"Before SMOTE :\" , Counter(y))\n",
    "print(\"After SMOTE :\" , Counter(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BiL9fgfY-7V"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns \r\n",
    "sns.countplot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBil2vIfWLXy"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bB3Fd_4WLXy"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf=SVC()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLpLkAsiWLXz"
   },
   "outputs": [],
   "source": [
    "pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSMZuozXWLXz"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbXPCXWiWLX0"
   },
   "outputs": [],
   "source": [
    "x=S.stem(str(input()).lower())\n",
    "f=[]\n",
    "f.append(x)\n",
    "pred=clf.predict(tfidf.transform(f))\n",
    "\n",
    "arr=['foul','penalty','goal','red card','yellow card']\n",
    "print(arr[pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWNTeTDCWLX1"
   },
   "outputs": [],
   "source": [
    "tweets=list(df['Tweet'])\n",
    "dates=list(df['Date'])\n",
    "classes=[]\n",
    "datess=[]\n",
    "times=[]\n",
    "tweetss=[]\n",
    "for i in indexes:\n",
    "    tweet=nlp(tweets[i])\n",
    "    my_tweet=[]\n",
    "    for j in tweet:\n",
    "        if j.text in nlp.Defaults.stop_words or j.is_punct is True:\n",
    "            pass\n",
    "        else:\n",
    "            my_tweet.append(S.stem(j.text.lower()))\n",
    "    new_tweet=' '.join(my_tweet)\n",
    "    f=[]\n",
    "    f.append(new_tweet)\n",
    "    pred=clf.predict(tfidf.transform(f))\n",
    "    arr=['foul','penalty','goal','red card','yellow card']\n",
    "    classs=arr[pred[0]]\n",
    "    my_tweett=tweets[i]\n",
    "    date,time=dates[i].split()\n",
    "    classes.append(classs)\n",
    "    tweetss.append(my_tweett)\n",
    "    datess.append(date)\n",
    "    times.append(time)\n",
    "df=pd.DataFrame()\n",
    "df['tweet']=tweetss\n",
    "df['date']=datess\n",
    "df['time']=times\n",
    "df['type']=classes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMAhELM7jeLR"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Goe5Fs9CWLX2"
   },
   "outputs": [],
   "source": [
    "df.to_csv('data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fPorZKVWLX3"
   },
   "outputs": [],
   "source": [
    "len(tweetss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwHoQapqWLX3"
   },
   "outputs": [],
   "source": [
    "Counter(list(pd.read_csv('data2.csv')['type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCxjDxSpWLX4"
   },
   "outputs": [],
   "source": [
    "len(list(set(tweetss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Xzv7BrNWLX4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SoccerEventsSummarizationAndPrediction2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlpfinal",
   "language": "python",
   "name": "nlpfinal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
